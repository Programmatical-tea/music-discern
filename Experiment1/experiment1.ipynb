{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: (2022-07-28~)\n",
    "- - -\n",
    "#### 0. Preprocessing / (Done on seperate file)\n",
    "Urbansound8k Dataset i){8732(<=4s).wav files/10 folders(must be separated)} => Noise data    \n",
    "MTG-jamendo Dataset i){}=> Music data   \n",
    "For easy labeling, we need to save the labels along with the data ( X.npy = [ data , label ] )\n",
    "\n",
    "#### 1. Initialize input pipeline\n",
    "\n",
    "\n",
    "#### 2. Model initialization\n",
    "\n",
    "\n",
    "#### 3. Training & Evaluation\n",
    "\n",
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, losses\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "autotune = tf.data.experimental.AUTOTUNE # solution to AttributeError: when using tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            #tf.config.experimental.set_virtual_device_configuration(gpu, [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*11)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9546113498350660651\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9920774144\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17173713175275497283\n",
      "physical_device_desc: \"device: 0, name: NVIDIA TITAN V, pci bus id: 0000:09:00.0, compute capability: 7.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initializing Input Pipeline   \n",
    "(planned 22.08.08)   \n",
    "* First define the raw tf.data.Datasets.   \n",
    "* Make a function that preprocesses the training datasets.\n",
    "* Use tf.data.Dataset.map to create the fully processed dataset.\n",
    "* Then make a function that finds the labels for each of the training datasets.   \n",
    "* Use tf.data.Dataset.map to create the label Dataset.   \n",
    "* Then combine them with tf.data.Dataset.zip.   \n",
    "* Then Shuffle & Configure for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 513*345\n",
    "IMAGE_DIM = [513,345,1]\n",
    "\n",
    "# Training\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('C:/Users/KSAI/jaewon_projectfolder/music-discern/Datasets/Urbansound8K/processed/fold1'), WindowsPath('C:/Users/KSAI/jaewon_projectfolder/music-discern/Datasets/Urbansound8K/processed/fold2'), WindowsPath('C:/Users/KSAI/jaewon_projectfolder/music-discern/Datasets/Urbansound8K/processed/fold3'), WindowsPath('C:/Users/KSAI/jaewon_projectfolder/music-discern/Datasets/Urbansound8K/processed/fold4')]\n",
      "[WindowsPath('C:/Users/KSAI/jaewon_projectfolder/music-discern/Datasets/MTGJamendo/processed/fold1'), WindowsPath('C:/Users/KSAI/jaewon_projectfolder/music-discern/Datasets/MTGJamendo/processed/fold2'), WindowsPath('C:/Users/KSAI/jaewon_projectfolder/music-discern/Datasets/MTGJamendo/processed/fold3'), WindowsPath('C:/Users/KSAI/jaewon_projectfolder/music-discern/Datasets/MTGJamendo/processed/fold4')]\n"
     ]
    }
   ],
   "source": [
    "base_path = pathlib.Path('C:/Users/KSAI/jaewon_projectfolder/music-discern/') # Edit on other computers\n",
    "base_path_dataset = pathlib.Path('C:/Users/KSAI/jaewon_projectfolder/music-discern/Datasets/') # Edit on other computers\n",
    "\n",
    "#Urbansound is nested in Datasets/Urbansound8K/audio/fold**\n",
    "#Urbansound is already separated into batches, which need to be preserved.\n",
    "urban_metadata_path = pathlib.Path(base_path_dataset/'Urbansound8K/metadata')\n",
    "urban_audio_folders_path = pathlib.Path(base_path_dataset/'Urbansound8K/processed')\n",
    "urban_audio_path_list = [x for x in urban_audio_folders_path.iterdir()]\n",
    "temp = urban_audio_path_list.pop(1)\n",
    "urban_audio_path_list.append(temp)\n",
    "urban_audio_path_list = urban_audio_path_list[:4]\n",
    "#Jamendo is nested in Datasets/MTGJamendo/audio\n",
    "#Jamendo is not separated in batches, so we need to separate it into 10 batches, matching urbansound.\n",
    "jamendo_metadata_path = pathlib.Path(base_path_dataset/'MTGJamendo/metadata')\n",
    "jamendo_audio_folders_path = pathlib.Path(base_path_dataset/'MTGJamendo/processed')\n",
    "jamendo_audio_path_list = [x for x in jamendo_audio_folders_path.iterdir()]\n",
    "temp = jamendo_audio_path_list.pop(1)\n",
    "jamendo_audio_path_list.append(temp)\n",
    "jamendo_audio_path_list = jamendo_audio_path_list[:4]\n",
    "\n",
    "#for later -> add a path for any .wav file that I want to observe.\n",
    "test_subjects_path = pathlib.Path(\"./\")\n",
    "\n",
    "save_weights_path = pathlib.Path(base_path/'Experiment1/model_checkpoints')\n",
    "save_weights_A_path = pathlib.Path(save_weights_path/'model_A')\n",
    "save_weights_B_path = pathlib.Path(save_weights_path/'model_B')\n",
    "\n",
    "Train = [0,1,2]\n",
    "Test = [3] #Seperation, for later evaluation in Training step B\n",
    "\n",
    "print(urban_audio_path_list)\n",
    "print(jamendo_audio_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_for_training_A = \"empty\"\n",
    "dataset_for_training_B_train = \"empty\"\n",
    "dataset_for_training_B_test = \"empty\"\n",
    "\n",
    "dataset_for_training_A = tf.data.Dataset.list_files(str(urban_audio_folders_path/'*/*.npy'))\n",
    "dataset_for_training_A = dataset_for_training_A.concatenate( tf.data.Dataset.list_files(str(jamendo_audio_folders_path/'*/*.npy')) )\n",
    "\n",
    "for k in Train:\n",
    "    temp_path_urban = str(urban_audio_path_list[k])\n",
    "    temp_path_jam = str(jamendo_audio_path_list[k])\n",
    "    if dataset_for_training_B_train == \"empty\":\n",
    "        dataset_for_training_B_train = tf.data.Dataset.list_files(temp_path_urban + '/*.npy')\n",
    "        dataset_for_training_B_train = dataset_for_training_B_train.concatenate( tf.data.Dataset.list_files(temp_path_jam + '/*.npy') )\n",
    "    else:\n",
    "        dataset_for_training_B_train = dataset_for_training_B_train.concatenate( tf.data.Dataset.list_files(temp_path_urban + '/*.npy') )\n",
    "        dataset_for_training_B_train = dataset_for_training_B_train.concatenate( tf.data.Dataset.list_files(temp_path_jam + '/*.npy') )\n",
    "\n",
    "for k in Test:\n",
    "    temp_path_urban = str(urban_audio_path_list[k])\n",
    "    temp_path_jam = str(jamendo_audio_path_list[k])\n",
    "    if dataset_for_training_B_test == \"empty\":\n",
    "        dataset_for_training_B_test = tf.data.Dataset.list_files(temp_path_urban + '/*.npy')\n",
    "        dataset_for_training_B_test = dataset_for_training_B_test.concatenate( tf.data.Dataset.list_files(temp_path_jam + '/*.npy') )\n",
    "    else:\n",
    "        dataset_for_training_B_test = dataset_for_training_B_test.concatenate( tf.data.Dataset.list_files(temp_path_urban + '/*.npy') )\n",
    "        dataset_for_training_B_test = dataset_for_training_B_test.concatenate( tf.data.Dataset.list_files(temp_path_jam + '/*.npy') )\n",
    "\n",
    "# returns dataset for training A, dataset for training B Train, dataset for training B Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "- - - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_for_training_A = dataset_for_training_A.take(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'C:\\\\Users\\\\KSAI\\\\jaewon_projectfolder\\\\music-discern\\\\Datasets\\\\Urbansound8K\\\\processed\\\\fold10\\\\129750-2-0-45_noise_0.npy', shape=(), dtype=string)\n",
      "tf.Tensor(b'noise', shape=(), dtype=string)\n",
      "float32\n",
      "tf.Tensor(\n",
      "[[ -1.7809997  -1.8693118  -2.3372455 ... -19.886133  -19.037477\n",
      "  -17.172678 ]\n",
      " [-15.650198  -15.010642  -15.059572  ... -12.941454  -19.211908\n",
      "  -13.332477 ]\n",
      " [-15.16608   -17.65097   -13.223452  ...  -7.5555587  -9.345667\n",
      "   -6.359665 ]\n",
      " ...\n",
      " [-55.453754  -61.59188   -59.0893    ... -20.992048  -21.870554\n",
      "  -28.02628  ]\n",
      " [-27.445696  -26.602354  -24.237127  ... -18.1518    -18.283327\n",
      "  -18.30041  ]\n",
      " [-17.97881   -18.248453  -19.206882  ... -22.325317  -22.325993\n",
      "  -22.326046 ]], shape=(513, 345), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for f in dataset_for_training_A.take(1):\n",
    "    print(f)\n",
    "    print(tf.strings.split( tf.strings.split( f,os.sep )[-1],sep=\"_\" )[1])\n",
    "    A = np.load(f.numpy(),allow_pickle=True)\n",
    "    print(A.dtype)\n",
    "    img = tf.io.read_file(f)\n",
    "    img = tf.io.decode_raw(img,tf.float32)\n",
    "    img = tf.slice(img,begin=[32],size=[IMAGE_SIZE])\n",
    "    img = tf.reshape(img,[513,345])\n",
    "    print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    #make the images into spectrograms\n",
    "    # processed_img = tf.pow(tf.abs(image),2) edited 2022-08-29, takes to much ram, so done in the preprocessing step.\n",
    "    processed_img = image\n",
    "    #normalize the images?\n",
    "    return processed_img\n",
    "\"\"\"\n",
    "def process_path_A(path):\n",
    "    #for training A, the label is just itself so we need to take that into account\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.io.decode_raw(img,tf.float32)#this changes too, 2022-08-29\n",
    "    img = tf.slice(img,begin=[1024//32],size=[IMAGE_SIZE]) # begin <- 1024//complex64\n",
    "    img = tf.reshape(img,IMAGE_DIM)\n",
    "    img = process_image(img)\n",
    "\n",
    "    label = img\n",
    "    return img, label\n",
    "\"\"\"\n",
    "\n",
    "def process_a(file_path):\n",
    "    n = np.load(file_path)\n",
    "    return np.reshape(n,[513,345,1])\n",
    "\n",
    "process_path_A = lambda input : tf.numpy_function(process_a, [input], [tf.float32])\n",
    "\n",
    "def process_path_B(path): #map_func\n",
    "    #extract the 2d array and the label\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.io.decode_raw(img,tf.float32) #this changes too, 2022-08-29\n",
    "    img = tf.slice(img,begin=[1024//32],size=[IMAGE_SIZE]) # begin <- 1024//complex64\n",
    "    img = tf.reshape(img,IMAGE_DIM)\n",
    "    img = process_image(img)\n",
    "\n",
    "    label = tf.strings.split( tf.strings.split( path, os.sep )[-1],sep=\"_\" )[1]\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_A = dataset_for_training_A.map(process_path_A,num_parallel_calls=autotune)\n",
    "dataset_B_train = dataset_for_training_B_train.map(process_path_B,num_parallel_calls=autotune)\n",
    "dataset_B_test = dataset_for_training_B_test.map(process_path_B,num_parallel_calls=autotune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(513, 345, 1), dtype=float32, numpy=\n",
       "array([[[ -5.2975945 ],\n",
       "        [  1.0981536 ],\n",
       "        [  5.388746  ],\n",
       "        ...,\n",
       "        [ -0.88134646],\n",
       "        [ -2.6216993 ],\n",
       "        [-12.708124  ]],\n",
       "\n",
       "       [[ -5.100108  ],\n",
       "        [ -0.9640103 ],\n",
       "        [  3.0595672 ],\n",
       "        ...,\n",
       "        [ -3.6349382 ],\n",
       "        [ -1.5287029 ],\n",
       "        [ -5.2050905 ]],\n",
       "\n",
       "       [[ -6.1471977 ],\n",
       "        [ -8.931383  ],\n",
       "        [ -4.3648906 ],\n",
       "        ...,\n",
       "        [ -2.4978356 ],\n",
       "        [ -1.6882263 ],\n",
       "        [ -4.9211063 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-43.836678  ],\n",
       "        [-47.955086  ],\n",
       "        [-63.159134  ],\n",
       "        ...,\n",
       "        [-63.159134  ],\n",
       "        [-42.849052  ],\n",
       "        [-34.702072  ]],\n",
       "\n",
       "       [[-44.564053  ],\n",
       "        [-49.359848  ],\n",
       "        [-63.159134  ],\n",
       "        ...,\n",
       "        [-63.159134  ],\n",
       "        [-42.813545  ],\n",
       "        [-34.702793  ]],\n",
       "\n",
       "       [[-44.891705  ],\n",
       "        [-50.14788   ],\n",
       "        [-63.159134  ],\n",
       "        ...,\n",
       "        [-63.159134  ],\n",
       "        [-42.834644  ],\n",
       "        [-34.703766  ]]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset_A))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_for_performance(ds):\n",
    "    ds = ds.cache()\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=autotune)\n",
    "    return ds\n",
    "\n",
    "dataset_A = configure_for_performance(dataset_A)\n",
    "dataset_B_test = configure_for_performance(dataset_B_test)\n",
    "dataset_B_train = configure_for_performance(dataset_B_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 513, 345, 1)\n",
      "(1, 256, 172, 16)\n",
      "(1, 128, 86, 8)\n",
      "(1, 257, 173, 8)\n",
      "(1, 515, 347, 16)\n",
      "(1, 513, 345, 1)\n",
      "(1, 513, 345, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = layers.Conv2D(16, (3,3), activation='relu', padding='valid', strides=2)\n",
    "b = layers.Conv2D(8, (3,3), activation='relu', padding='same', strides=2)\n",
    "c = layers.Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='valid')\n",
    "d = layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='valid')\n",
    "e = layers.Conv2D(1, kernel_size=(3,3), activation='sigmoid', padding='valid')\n",
    "\n",
    "input_shape = (1,513,345,1)\n",
    "x = tf.random.normal(input_shape)\n",
    "\n",
    "print(input_shape)\n",
    "y = a(x)\n",
    "print(y.shape)\n",
    "y = b(y)\n",
    "print(y.shape)\n",
    "y = c(y)\n",
    "print(y.shape)\n",
    "y = d(y)\n",
    "print(y.shape)\n",
    "y = e(y)\n",
    "print(y.shape)\n",
    "y = e(d(c(b(a(x)))))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "#when the input shape is an odd number, even number of strides coupled with 'same' padding makes the output shape different from the imput shape.\n",
    "#Therefore by trial and error this valid, same, valid, valid, valid padding structure was found, not sure if it is accurate\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.InputLayer(input_shape = IMAGE_DIM , batch_size= batch_size),\n",
    "            layers.Conv2D(16, (3,3), activation='relu', padding='valid', strides=2),\n",
    "            layers.Conv2D(8, (3,3), activation='relu', padding='same', strides=2), \n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='valid'),\n",
    "            layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='valid'),\n",
    "            layers.Conv2D(1, kernel_size=(3,3), activation='sigmoid', padding='valid') \n",
    "        ])\n",
    "    \n",
    "    def __call__(self, x, training=False):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "Model_A = Autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, Model_A):\n",
    "        super(Classifier, self).__init__()\n",
    "        #comes after the encoding\n",
    "        self.classifer_layer = tf.keras.Sequential([\n",
    "            layers.InputLayer(input_shape=[128,86,8], batch_size= batch_size),\n",
    "            layers.Conv2D(8, (3,3), activation='relu', padding='same', strides=2),\n",
    "            layers.Conv2D(4, (3,3), activation='relu', padding='same', strides=2),\n",
    "            layers.Conv2D(2, (3,3), activation='relu', padding='same', strides=2),\n",
    "            layers.Conv2D(1, (3,3), activation='relu', padding='same', strides=2),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(16, activation='relu'),\n",
    "            layers.Dense(1, activation='softmax')\n",
    "        ])\n",
    "        self.Model_A = Model_A.encoder # Probablility of deepcopy, not sure. If accuracy is terrible this may be the suspect\n",
    "\n",
    "    def __call__(self,x, training=False):\n",
    "        compressed = self.Model_A(x)\n",
    "        return self.classifer_layer(compressed)\n",
    "\n",
    "Model_B = Classifier(Model_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_A.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss=tf.keras.losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_B.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback function that saves the weights periodically, and shows the reconstructed images periodically\n",
    "class Monitor_A(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        #_, ax = plt.subplots(1,2, figsize=(21,7)\n",
    "        #for k,k in dataset_A.take(1):\n",
    "        #    changed = self.model(k)\n",
    "        #    clear_output(wait=True)\n",
    "        #    ax[0].imshow(k[0])\n",
    "        #    ax[1].imshow(changed[0])\n",
    "        #    ax[0].set_title(\"Input image\")\n",
    "        #    ax[1].set_title(\"Translated image\")\n",
    "        #    ax[0].axis(\"off\")\n",
    "        #    ax[1].axis(\"off\")\n",
    "        \n",
    "        for k,k in dataset_A.take(1):\n",
    "            plt.figure(figsize=(21, 5))\n",
    "\n",
    "            n_fft = 1024\n",
    "            hop_length = n_fft//4 #256\n",
    "            sr = 22050\n",
    "            plt.subplot(1, 2, 1)\n",
    "            librosa.display.specshow(tf.reshape(k[0],[513,345]).numpy(), sr=sr, hop_length=hop_length, x_axis='time', y_axis='linear')\n",
    "            plt.colorbar(format='%+2.0f dB')\n",
    "\n",
    "            plt.subplot(1, 2, 2)\n",
    "            changed = self.model(k)\n",
    "            librosa.display.specshow(tf.reshape(changed[0],[513,345]).numpy(), sr=sr, hop_length=hop_length, x_axis='time', y_axis='linear')\n",
    "            plt.colorbar(format='%+2.0f dB')\n",
    "\n",
    "        if (epoch) % 5 == 0:\n",
    "            self.model.save_weights(pathlib.Path(save_weights_A_path/\"{epoch:04}.h5\"))\n",
    "    \n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback function that saves the weights periodically, and shows the reconstructed images periodically\n",
    "class Monitor_B(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        if (epoch) % 5 == 0:\n",
    "            self.model.save_weights(pathlib.Path(save_weights_B_path/\"{epoch:04}.h5\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    c:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:862 train_function  *\n        return step_function(self, iterator)\n    c:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:852 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845 run_step  **\n        outputs = model.train_step(data)\n    c:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    c:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:541 minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    c:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:641 apply_gradients\n        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n    c:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\utils.py:76 filter_empty_gradients\n        ([v.name for _, v in grads_and_vars],))\n\n    ValueError: No gradients provided for any variable: ['conv2d_3/kernel:0', 'conv2d_3/bias:0', 'conv2d_4/kernel:0', 'conv2d_4/bias:0', 'conv2d_transpose_2/kernel:0', 'conv2d_transpose_2/bias:0', 'conv2d_transpose_3/kernel:0', 'conv2d_transpose_3/bias:0', 'conv2d_5/kernel:0', 'conv2d_5/bias:0'].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12620\\4236551670.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/gpu:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_A\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mMonitor_A\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1191\u001b[0m                 _r=1):\n\u001b[0;32m   1192\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1193\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1194\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 760\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3065\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3066\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3067\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3308\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    c:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:862 train_function  *\n        return step_function(self, iterator)\n    c:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:852 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845 run_step  **\n        outputs = model.train_step(data)\n    c:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    c:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:541 minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    c:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:641 apply_gradients\n        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n    c:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\utils.py:76 filter_empty_gradients\n        ([v.name for _, v in grads_and_vars],))\n\n    ValueError: No gradients provided for any variable: ['conv2d_3/kernel:0', 'conv2d_3/bias:0', 'conv2d_4/kernel:0', 'conv2d_4/bias:0', 'conv2d_transpose_2/kernel:0', 'conv2d_transpose_2/bias:0', 'conv2d_transpose_3/kernel:0', 'conv2d_transpose_3/bias:0', 'conv2d_5/kernel:0', 'conv2d_5/bias:0'].\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    history = Model_A.fit(dataset_A, batch_size=10, epochs=100, callbacks=[Monitor_A()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2cf0a7e7148>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "#plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": " Cast string to float is not supported\n\t [[node sparse_categorical_crossentropy/Cast (defined at C:\\Users\\KSAI\\AppData\\Local\\Temp\\ipykernel_11068\\3073328163.py:2) ]] [Op:__inference_train_function_2158231]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11068\\3073328163.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/gpu:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel_B\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_B_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mMonitor_B\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_B_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1191\u001b[0m                 _r=1):\n\u001b[0;32m   1192\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1193\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1194\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3040\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1964\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\Users\\KSAI\\anaconda3\\envs\\jjw\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnimplementedError\u001b[0m:  Cast string to float is not supported\n\t [[node sparse_categorical_crossentropy/Cast (defined at C:\\Users\\KSAI\\AppData\\Local\\Temp\\ipykernel_11068\\3073328163.py:2) ]] [Op:__inference_train_function_2158231]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    history = Model_B.fit(dataset_B_train, batch_size=batch_size, epochs=100, callbacks=[Monitor_B()], validation_data=dataset_B_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](/Experiment1abstract.jpg?raw=true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('jjw')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac704e6022295486845fbd340b0b7862caa0be3550d859b105d48f34f4ecc39f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
