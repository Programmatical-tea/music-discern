{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "import librosa\n",
    "import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Used for listening to audio samples in ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def Audio(audio: np.ndarray, sr: int):\n",
    "    \"\"\"\n",
    "    Use instead of IPython.display.Audio as a workaround for VS Code.\n",
    "    `audio` is an array with shape (channels, samples) or just (samples,) for mono.\n",
    "    \"\"\"\n",
    "\n",
    "    if np.ndim(audio) == 1:\n",
    "        channels = [audio.tolist()]\n",
    "    else:\n",
    "        channels = audio.tolist()\n",
    "\n",
    "    return IPython.display.HTML(\"\"\"\n",
    "        <script>\n",
    "            if (!window.audioContext) {\n",
    "                window.audioContext = new AudioContext();\n",
    "                window.playAudio = function(audioChannels, sr) {\n",
    "                    const buffer = audioContext.createBuffer(audioChannels.length, audioChannels[0].length, sr);\n",
    "                    for (let [channel, data] of audioChannels.entries()) {\n",
    "                        buffer.copyToChannel(Float32Array.from(data), channel);\n",
    "                    }\n",
    "            \n",
    "                    const source = audioContext.createBufferSource();\n",
    "                    source.buffer = buffer;\n",
    "                    source.connect(audioContext.destination);\n",
    "                    source.start();\n",
    "                }\n",
    "            }\n",
    "        </script>\n",
    "        <button onclick=\"playAudio(%s, %s)\">Play</button>\n",
    "    \"\"\" % (json.dumps(channels), sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Path variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Checking audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Preprocessing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d5c1156327dacead463cc502c55ebae8ce9c8c01979cf154173ff808e75bf55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
